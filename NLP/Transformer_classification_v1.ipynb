{"cells":[{"cell_type":"markdown","metadata":{"id":"7-Quw0_gXyDR"},"source":["# Sentiment Classification using Transformer"]},{"cell_type":"markdown","source":["Before diving into this notebook, we strongly recommend \n","going through **all** the chapters of the official [ðŸ¤— Hugging Face course](https://huggingface.co/course/chapter1/1). This will make it much easier for \n","you to follow this notebook and transfer the knowledge to **your** tasks."],"metadata":{"id":"da6TrUsUZzi7"}},{"cell_type":"markdown","source":["In this notebook, we will simulate a real-world use \n","case and try to solve it using tools of the Hugging Face ecosystem.\n","\n","We strongly recommend using this notebook as a template/example to \n","solve **your** real-world use case."],"metadata":{"id":"H4mgysOXZZWD"}},{"cell_type":"markdown","source":["# **Defining Task, Dataset & Model**\n","\n","Before jumping into the actual coding part, it's important to have a clear definition of the use case that you would like to automate or partly automate.\n","A clear definition of the use case helps in identifying the most suitable task, dataset to use, and model to apply for your use case."],"metadata":{"id":"B_tTKBgzNNP0"}},{"cell_type":"markdown","source":["## **Define your NLP task**\n","\n","Alright, let's dive into a hypothetical problem we wish to save using models of natural language processing. Let's assume, we are selling a product and our customer support team receives thousands of messages including feedback, complaints, and questions which ideally should all be answered. \n","\n","Quickly, it becomes obvious though that customer support is by no means able to reply to every message. Thus, we decide to only reply \n","to the most unsatisfied custmoers and set the goal of replying to 100% of very unsatisfied messages.\n","\n","Assuming that a) messages of very unsatisfied customers represent only a fraction of all messages and b) that we can filter out unsatisfied messages in an automated way, customer support should be able to reach this goal.\n","\n","To filter out unsatisfied messages in an automated way, we plan on applying natural language processing technologies. \n","\n","\n","The first step is now to map our use case - *filtering out unsatisfied messages* - to a natural language processing task.\n","\n","To do so, it is recommended to go over all available tasks on the Hugging Face Hub [here](https://huggingface.co/tasks). If you are not sure which task applies to your use case, you should click on all of the different tasks to better understand them, *e.g.* \n","\n","Automatically replying  The task of finding messages of the most unsatisfied customers can be labeled as a text classification task: Classify a message into one of *very unsatisfied*, *unsatisfied*, *neutral*, *satisfied*, or *very satisfied*.\n","\n"],"metadata":{"id":"SCP5jic6ZCEG"}},{"cell_type":"markdown","source":["## **Find suitable datasets**\n","\n","Having decided on the task, next we should find the data the model will be trained on. This is usually more important for the downstream performance of your use case than picking the right model architecture.\n","Keep in mind that a model is **only as good as the data it has been trained on**. Thus, we should be very careful when curating and/or selecting the dataset.\n","\n","Since we consider the hypothetical use case of *filtering out unsatisfied messages*, let's look into what datasets are available to us.\n","\n","For your real-world use case, it is **very likely** that you have internal data that best represents the actual data your NLP system is supposed to handle. Therefore, you should use such internal data to train your NLP system.\n","It can nevertheless be helpful to also include publicly available to improve the generalizability of your model.\n","\n","Let's take a look at all available Datasets on the [Hugging Face Hub](https://huggingface.co/datasets). On the left side, you can filter the datasets according to *Task Categories* as well as *Tasks* which are more specific. Our use case corresponds to *Text Classification* -> *Sentiment Analysis* so let's select [these filters](https://huggingface.co/datasets?task_categories=task_categories:text-classification&task_ids=task_ids:sentiment-classification&sort=downloads). We are left with *ca.* 80 datasets at the time of writing this notebook. Two aspects should be evaluated when picking a dataset:\n","\n","- **Quality**: Is the dataset of high quality? More specifically: Does the data correspond to the data you expect to deal with in your use case? Is the data diverse, unbiased, ...?\n","- **Size**: How big is the dataset? Usually one can safely say the bigger the dataset, the better.\n","\n","It's quite difficult to efficiently evaluate whether a dataset is of high quality and it's even more difficult to know whether and how the dataset is biased.\n"," An efficient and reasonable heuristic for high quality is to look at the download statistics. The more downloads, the more usage, the higher chance that the dataset is of high quality. The size is easy to evaluate as it can usually be quickly read upon. Let's take a look at the most downloaded datasets:\n","\n","- [Glue](https://huggingface.co/datasets/glue)\n","- [Amazon polarity](https://huggingface.co/datasets/amazon_polarity)\n","- [Tweet eval](https://huggingface.co/datasets/tweet_eval)\n","- [Yelp review full](https://huggingface.co/datasets/yelp_review_full)\n","- [Amazon reviews multi](https://huggingface.co/datasets/amazon_reviews_multi)\n","\n","Now we can inspect those datasets in more detail by reading through the dataset card which ideally should give all relevant and important information. In addition, the [dataset viewer](https://huggingface.co/datasets/glue/viewer/cola/test) is an incredibly powerful tool to inspect whether the data suits your use case.\n","\n","Let's quickly go over the dataset cards of the models above: \n","- *GLUE* is a collection of small datasets that mostly serves as a means to compare new model architectures for researchers. The datasets are too small and don't correspond enough to our use case.\n","- *Amazon polarity* is huge and a well-suited dataset for customer feedback since the data deals with customer reviews. However, it only has binary labels (positive/negative) whereas we are looking for more granularity in the sentiment classification. \n","- *Tweet eval* uses different emojis as labels which cannot that easily be mapped to a scale going from unsatisfied to satisfied.\n","- *Amazon reviews multi* seems to be the most suited dataset here. We have sentiment labels ranging from 1-5 corresponding to 1-5 stars on Amazon. These labels can very well be mapped to *very unsatisfied, unsatisfied, neutral, satisfied, very satisfied*. Having inspected some examples on [the dataset viewer](https://huggingface.co/datasets/amazon_reviews_multi/viewer/en/train) we can see that the reviews look very similar to how customer feedback reviews would look, so this seems like a very good dataset. In addition, each review has a `product_category` label so we could even go as far as to only use reviews of a product category that corresponds to the one we are working in. The dataset is multi-lingual, but we are just interested in the English version for now.\n","- *Yelp review full* looks like a very suitable dataset. It's large and contains product reviews and sentiment labels from 1 to 5. Sadly, the dataset viewer is not working here at the moment and the dataset card is also relatively sparse requiring some more time to inspect the dataset. At this point, we should read the paper, but given the time-constraint of this blog post, we'll choose to go for *Amazon reviews multi*.\n","\n","As a conclusion, let's focus on the [*Amazon reviews multi*](https://huggingface.co/datasets/amazon_reviews_multi) dataset considering all training examples.\n","\n","As a final note, we recommend making use of Hub's dataset functionality even when working with private datasets. The Hugging Face Hub, Transformers, and Datasets are flawlessly integrated, which makes it trivial to use them in combination when training models.\n","\n","In addition, the Hugging Face Hub offers:\n","\n","- [A dataset viewer for every dataset](https://huggingface.co/datasets/amazon_reviews_multi)\n","- [Easy demoing of every model using widgets](https://huggingface.co/docs/hub/main#whats-a-widget)\n","- [Private and Public models](https://huggingface.co/docs/hub/adding-a-model#creating-a-repository)\n","- [Git version control for repositories](https://huggingface.co/docs/hub/main#whats-a-repository)\n","- [Highest security mechanisms](https://huggingface.co/docs/hub/security)"],"metadata":{"id":"k_MrbAHndCAy"}},{"cell_type":"markdown","source":["## **Find a suitable model**\n","\n","Having decided on the task and the dataset that best describes our use case, we can now look into choosing a model to be used.\n","\n","Most likely, you will have to fine-tune a pretrained model for your use case, but it is worth checking whether they are already fine-tuned models on the Hub that perform well. In this case, you might reach a higher performance by just continuing to fine-tune such a model on your dataset.\n","\n","Let's take a look at all models that have been fine-tuned on Amazon Reviews Multi, you can find the list of models on the bottom right corner - clicking on *Browse models trained on this dataset* you can see [a list of all models fine-tuned on the dataset that are publicly available](https://huggingface.co/models?dataset=dataset:amazon_reviews_multi). Note that we are only interested in the English version of the dataset because our customer feedback will only be in English. It looks like most of the most downloaded models are trained on the multi-lingual version of the dataset and those that don't seem to be multi-lingual have very little information or poor performance. At this point, \n","it might be more sensible to fine-tune a purely pretrained model instead of using one of the already fine-tuned ones shown in the link above.\n","\n","Alright, the next step now is to find a suitable pretrained model to be used for fine-tuning. This is actually more difficult than it seems given the large amount of pretrained and fine-tuned models that are the [Hugging Face Hub](https://huggingface.co/models) . The best option is usually to simply try out a variety of different models to see which one performs best. \n","We still haven't found the perfect way of comparing different model checkpoints to each other at Hugging Face, but we provide some resources that are worth looking into:\n","\n","- The [model summary](https://huggingface.co/docs/transformers/model_summary) gives a short overview of different model architectures.\n","- A task-specific search on the Hugging Face Hub, *e.g.* [a search on text-classification models](https://huggingface.co/models), shows you the most downloaded checkpoints which is also an indication of how well those checkpoints perform.\n","\n","Both of the above resources are currently however a bit suboptimal. The model summary is not always kept up to date. The speed at which new model architectures are released and old model architectures become outdated makes it extremely difficult to have an up-to-date summary of all model architectures.\n","Similarly, it doesn't necessarily mean that the most downloaded model checkpoint is the best one. E.g. [`bert-base-cased`](https://huggingface.co/bert-base-uncased) is amongst the most downloaded model checkpoints but is not the best performing checkpoint anymore.  \n","\n","The best is often to try out a variety of different model architectures, stay up to date with new model architectures by following experts in the field and checking well-known leaderboards.\n","\n","For text-classification, the important benchmarks to look at are [GLUE](https://gluebenchmark.com/leaderboard) and [SuperGLUE](https://super.gluebenchmark.com/leaderboard). Both benchmarks evaluate pretrained models on a variety of text-classification tasks, such as grammatical correctness, natural language inference, Yes/No question answering, etc..., which are quite similar to our target task of sentiment analysis. Thus, it is reasonable to choose one of the leading models of these benchmarks for our task.\n","\n","At the time of writing this notebook, the best performing models are very large models containing more than 10 billion parameters most of which are not open-sourced, *e.g.* *ST-MoE-32B*, *Turing NLR v5*, or\n","*ERNIE 3.0*. One of the top-ranking models that is easily accessible is [DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta). Because  Let's try out DeBERTa's newest base version - *i.e.* [`microsoft/deberta-v3-base`](https://huggingface.co/microsoft/deberta-v3-base)."],"metadata":{"id":"1IucFk0GQt0Q"}},{"cell_type":"markdown","source":["# **Training / Fine-tuning a model with ðŸ¤— Transformers and ðŸ¤— Datasets**\n","\n","In this section, we will jump into the technical details of how to \n","fine-tune a model end-to-end to be able to automatically filter out very unsatisfied customer feedback messages.\n","\n","Cool, let's start by installing all necessary pip packages and by setting up our code environment, then look into preprocessing the dataset and finally start training the model.\n","\n","The following notebook can be run online in a google colab pro with the GPU runtime environment enabled."],"metadata":{"id":"F4IQ0Bb6IRNQ"}},{"cell_type":"markdown","source":["## **Install all necessary packages**\n","\n","To begin with, let's install [`git-lfs`](https://git-lfs.github.com/) so that we can automatically upload our trained checkpoints to the Hub during training."],"metadata":{"id":"7ntAgMY2TKRx"}},{"cell_type":"markdown","metadata":{"id":"B683CTrxXyDY"},"source":["Also, we install the ðŸ¤— Transformers and ðŸ¤— Datasets libraries to run this notebook. Since we will be using [DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta-v2#debertav2) in this notebook, we also need to install the [`sentencepiece`](https://github.com/google/sentencepiece) library for its tokenizer."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OyR6R9jQXyDY","executionInfo":{"status":"ok","timestamp":1683390830926,"user_tz":-330,"elapsed":28412,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"outputs":[],"source":["%%capture\n","!pip install datasets transformers[sentencepiece]"]},{"cell_type":"markdown","source":["Next, let's login into our [Hugging Face account](https://huggingface.co/join) so that models are uploaded correctly under your name tag."],"metadata":{"id":"AnukCvT4UG-S"}},{"cell_type":"markdown","source":["## **Preprocess the dataset**\n","\n","Before we can start training the model, we should bring the dataset in a format \n","that is understandable by the model.\n","\n","Thankfully, the ðŸ¤— Datasets library makes this extremely easy as you will see in the following cells.\n","\n","The `load_dataset` function loads the dataset, nicely arranges it into predefined attributes, such as `review_body` and `stars`, and finally saves the newly arranged data using the [arrow format](https://arrow.apache.org/#:~:text=Format,data%20access%20without%20serialization%20overhead.) on disk. \n","The arrow format allows for fast and memory-efficient data reading and writing.\n","\n","Let's load and prepare the English version of the `amazon_reviews_multi` dataset."],"metadata":{"id":"XPz26fv8VC9k"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEz1Fcd36rOD","executionInfo":{"status":"ok","timestamp":1683390934075,"user_tz":-330,"elapsed":24847,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}},"outputId":"5524d57e-dc0b-45d9-deb0-148e9fb2a186"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"QctIiNOV2Csc","executionInfo":{"status":"ok","timestamp":1683390830927,"user_tz":-330,"elapsed":5,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["imdb_df = pd.read_csv('/content/drive/MyDrive/NLP/DLandNLP/NLP/labeledTrainData.tsv', sep = '\\t')"],"metadata":{"id":"qOPPwpiC2GEF","executionInfo":{"status":"ok","timestamp":1683390997811,"user_tz":-330,"elapsed":1733,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["imdb_df.info()"],"metadata":{"id":"IreapMMAze7c","outputId":"45fd31fc-2253-428f-cc37-4c5126aa37ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683391001743,"user_tz":-330,"elapsed":4,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 25000 entries, 0 to 24999\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         25000 non-null  object\n"," 1   sentiment  25000 non-null  int64 \n"," 2   review     25000 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 586.1+ KB\n"]}]},{"cell_type":"code","source":["imdb_df = imdb_df[['review', 'sentiment']]"],"metadata":{"id":"HW5zMvB98KxF","executionInfo":{"status":"ok","timestamp":1683391308787,"user_tz":-330,"elapsed":578,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"nVNUhUu47DZP","executionInfo":{"status":"ok","timestamp":1683391311438,"user_tz":-330,"elapsed":2,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["trainval, test = train_test_split(imdb_df, test_size = 0.2)\n","train, val = train_test_split(trainval, test_size = 0.1)"],"metadata":{"id":"AJILGT227Ih3","executionInfo":{"status":"ok","timestamp":1683391581305,"user_tz":-330,"elapsed":520,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["train.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrg3AICj7x_K","executionInfo":{"status":"ok","timestamp":1683391583244,"user_tz":-330,"elapsed":5,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}},"outputId":"a6c2feb4-7697-45e8-c297-19ac4d1bbfa3"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 18000 entries, 2192 to 1536\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   review     18000 non-null  object\n"," 1   sentiment  18000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 421.9+ KB\n"]}]},{"cell_type":"code","source":["train.shape, test.shape, val.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orgMyqtL71L4","executionInfo":{"status":"ok","timestamp":1683391584995,"user_tz":-330,"elapsed":1026,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}},"outputId":"b295bada-f559-48f8-d2d2-fa6690705d16"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((18000, 2), (5000, 2), (2000, 2))"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["train = train.reset_index()\n","test = test.reset_index()\n","val = val.reset_index()"],"metadata":{"id":"dlk7x3vG81Bx","executionInfo":{"status":"ok","timestamp":1683391587099,"user_tz":-330,"elapsed":2,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["Great, that was fast ðŸ”¥. Let's take a look at the structure of the dataset."],"metadata":{"id":"i5ikxNC0gtE8"}},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","\n","imdb_review_ds = {'train' : Dataset.from_pandas(train),\n","                  'test' : Dataset.from_pandas(test),\n","                  'val': Dataset.from_pandas(val)}"],"metadata":{"id":"TtaX3iCd1YaZ","executionInfo":{"status":"ok","timestamp":1683391629847,"user_tz":-330,"elapsed":1143,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["imdb_review = DatasetDict(imdb_review_ds)"],"metadata":{"id":"Iugkimcc1qf4","executionInfo":{"status":"ok","timestamp":1683391630704,"user_tz":-330,"elapsed":4,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["imdb_review"],"metadata":{"id":"83Z0ou-5AabP","outputId":"54672867-f5dc-4ad8-fbf2-b86b0542e69f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683391630704,"user_tz":-330,"elapsed":3,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['index', 'review', 'sentiment'],\n","        num_rows: 18000\n","    })\n","    test: Dataset({\n","        features: ['index', 'review', 'sentiment'],\n","        num_rows: 5000\n","    })\n","    val: Dataset({\n","        features: ['index', 'review', 'sentiment'],\n","        num_rows: 2000\n","    })\n","})"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["We have 200,000 training examples as well as 5000 validation and test examples. This sounds reasonable for training! We're only really interested in the input being the `\"review_body\"` column and the target being the `\"starts\"` column.\n","\n","Let's check out a random example."],"metadata":{"id":"fOugSjGyhDZT"}},{"cell_type":"code","source":["import random "],"metadata":{"id":"00CJdVMD2dw4","executionInfo":{"status":"ok","timestamp":1683391602876,"user_tz":-330,"elapsed":437,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["random_id = random.randint(0, 10000)\n","\n","print(\"Sentiment:\", imdb_review[\"train\"][random_id][\"sentiment\"])\n","print(\"Review:\", imdb_review[\"train\"][random_id][\"review\"])"],"metadata":{"id":"2LkoLF-DAd0g","outputId":"4485f886-7840-4a81-8012-415d81f48434","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683391669725,"user_tz":-330,"elapsed":4,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment: 1\n","Review: There were a lot of films made by Hollywood during the war years that were designed to drum up support for our troops from the public. Seen today, some might dismiss them or just see them as propaganda--which they technically are, but of a positive sort and meant to unify the nation. This film is a pretty effective and entertaining example of the genre--having a pretty realistic script and good production values. Pat O'Brien plays pretty much the same character he played in MANY other films (you know, the tough-talking, hard-driven but \\swell guy\\\"). Randolph Scott is, as always, competent and entertaining and the rest of the extras are excellent (look for a young Robert Ryan as one of the bombardiers in training). While the story is reminiscent of several other movies about our pilots and crews, the film is well-crafted enough to make it interesting and not too far-fetched. That it, perhaps, except for the very end--where the film is a bit over-the-top but also VERY satisfying. About the only serious negative, and this is mostly for nitpickers, is that some of the stock footage is somewhat sloppily integrated in the film and \\\"nuts\\\" like me who are both history teachers and airplane lovers will probably notice this--all others probably won't notice.\"\n"]}]},{"cell_type":"markdown","source":["The dataset is in a human-readable format, but now we need to transform it into a \"machine-readable\" format. Let's define the model repository which includes all utils necessary to preprocess and fine-tune the checkpoint we decided on."],"metadata":{"id":"jpQVg8EShhAV"}},{"cell_type":"markdown","source":["Next, we load the tokenizer of the model repository, which is a [DeBERTa's Tokenizer](https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.DebertaV2Tokenizer)."],"metadata":{"id":"oVWAfd0EidGD"}},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"],"metadata":{"id":"NOol5Oqv_-ZX","outputId":"bc203c13-985d-45cf-f673-0abab8877937","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["5b192b92dd7946c79a88bc3b07715f30","78d24079e4da4ad086c0d6ffd2d157a1","c0e065ad90cc4a559cec26bdc62611ce","8d19102eafc44acc8b9ded87ec8bb054","1c88b449ebce4f94afc378de9d924960","e7af254fb9fb44f5a93a9aef5202205f","a1354feaaac24603883b17fe92531998","66afe8e29e4b41839202d14043c40d36","6bedac0c05af465a9866910311be9fef","b8fe9890489c448cb21c3037af3d08e4","5e266556a5e8434fb92125bf04a93802","c76b0e8fd44f4add97490db7ceb6df63","63536cfa523d40b98f7ff1c7ac5b32a6","f969b9baf0394d388fea39f284606527","d5c3f19d02094c4186b355655979a0ea","a4446dd2ea1f432ba4d7a10cffa22274","7185b8bbf1564774a1cfc6c02e4d9347","3ec310d7ebf54bd59b38c2fa5ae479e4","08c8d7f2b3054f01ae82e7b99332b53d","13974833fd594ba9b30c5c666bf5b9e1","6a65fdb09124421bbca14a844efbc584","72c62f4a9af1468eabcda12e1ac493a7","e4bdce5859c34e7bb4bb1a4c157f15d8","8d20f99f8c954ac08d69b654b90af433","e42c818383df4c68a6e30e9beac7310d","ba6a6d3ee3a8416797b2bb82f565ecae","7e2423bfcec14c6684b6fc12934a3a2e","75762a239d7a4bbfa1a8dac2b8fb185a","bcc86a28ce474fb991ea12bdccd1e71b","d42a2eb1e5a4421ab7f98b361550bb2d","b593508ddd254dc4a7307a9790f45d63","64dcb24cc59245bbb06247886951ad86","40bd854226cd4c939da1e6e751165a6c","8bde3b8308e247f795bb8feb2fa1bd31","9d16d60b60364a7e9030a8309e802661","2ad4db497cd745dc856f699ba0bd16d2","563387678b9f48ffb5b21b2c22041495","aa0b8a7adcfb454287172ab77ab20bfe","edacec37cc294af0b4f6aef0230188c2","ebea0751290a4531b0f6c73efbe8dd53","715e1b3fcb7a427aa003dc3d0fd8d589","1ca41bfa100f431dba8f97d3626006c5","675bab324e6c4ec3b95059696fcdae4e","f7b0882ecc2c48a1b42257ee39316686"]},"executionInfo":{"status":"ok","timestamp":1683391710479,"user_tz":-330,"elapsed":3530,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b192b92dd7946c79a88bc3b07715f30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76b0e8fd44f4add97490db7ceb6df63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4bdce5859c34e7bb4bb1a4c157f15d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bde3b8308e247f795bb8feb2fa1bd31"}},"metadata":{}}]},{"cell_type":"markdown","source":["As mentioned before, we will use the `\"review_body\"` as the model's input and `\"stars\"` as the model's target. Next, we make use of the tokenizer to transform the input into a sequence of token ids that can be understood by the model. The tokenizer does exactly this and can also help you to limit your input data to a certain length to not run into a memory issue. Here, we limit \n","the maximum length to 128 tokens which in the case of DeBERTa corresponds to roughly 100 words which in turn corresponds to *ca.* 5-7 sentences. Looking at the [dataset viewer](https://huggingface.co/datasets/amazon_reviews_multi/viewer/en/test) again, we can see that this covers pretty much all training examples. \n","**Important**: This doesn't mean that our model cannot handle longer input sequences, it just means that we use a maximum length of 128 for training since it covers 99% of our training and we don't want to waste memory. Transformer models have shown to be very good at generalizing to longer sequences after training.\n","\n","If you want to learn more about tokenization in general, please have a look at [the Tokenizers docs](https://huggingface.co/course/chapter6/1?fw=pt).\n","\n","The labels are easy to transform as they already correspond to numbers in their raw form, *i.e.* the range from 1 to 5. Here we just shift the labels into the range 0 to 4 since indexes usually start at 0.\n","\n","Great, let's pour our thoughts into some code. We will define a `preprocess_function` that we'll apply to each data sample. "],"metadata":{"id":"-oBZK_6Gizrz"}},{"cell_type":"code","source":["def preprocess_function(example):\n","    output_dict = tokenizer(example[\"review\"], max_length=512, truncation=True)\n","    output_dict[\"labels\"] = example[\"sentiment\"]\n","    return output_dict"],"metadata":{"id":"jHHiqx2xEWwC","executionInfo":{"status":"ok","timestamp":1683392438158,"user_tz":-330,"elapsed":716,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["To apply this function to all data samples in our dataset, we just use the [`map`](https://huggingface.co/docs/datasets/master/en/package_reference/main_classes#datasets.Dataset.map) method of the `amazon_review` object we created earlier. This will apply the function on all the elements of all the splits in `amazon_review`, so our training, validation, and testing data will be preprocessed in one single command. We run the mapping function in `batched=True` mode to speed up the process and also remove all columns since we don't need them anymore for training."],"metadata":{"id":"OLNx1f4gqPjB"}},{"cell_type":"code","source":["tokenized_datasets = imdb_review.map(preprocess_function, \n","                                     batched=True, \n","                                     remove_columns=imdb_review[\"train\"].column_names)"],"metadata":{"id":"hH_cz_O-LfJf","colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["fbc28f8a36d44e57a92eefd10f7eac4a","1ba8fc08d4a742858d3cbfcc281c6cac","d15a615e2fc7455088998592efa1bcde","b392f9165c2148a0b53352c3f3ed7f23","c9562cba11ab42cb8d2cd4a8cdf3033a","2a9a837e329e4d20a524c3ac23bc8643","3ce6e759fb6d457b836bfa58d2422e54","99ab38cd80aa441499879577afaa678f","8ee75a5897ff4d3d9c19fd7383a47c0c","62f63c91ae7945be97e388393ca9b804","a315d0cff5794162b66829806c133db9","3a8967e5fed04643b392bee2987da6e5","59af80c824694b83b87887e37e953d2e","edf3b148d23744589c6e18d33dd4d284","07de1bab450942c7b3a43bafdc7ac58f","dd42611eaad84f20b021e1d59ccd8dc9","eb589136d86e40409f048f4e3d2fe2e0","490e6460672f4888b22f6f028781f916","2a35bb009d934cbd879f346ac678fece","e67b7afa32f0498a8bf072c76f9f5378","ad02b3c6318b486687f68577a5ded513","1e14e1fb215549caa55b053c1a9082ac","800ce60c32624fd98b0d2122c331b279","c141e31dbb2442ce8fe69e364296cb91","aad9cf7df35e433a90eb4de22ae5e088","46f1838f9ac948b28ffdb3911dddf0db","8873125d0c81449f9354a24538991605","eb9e4d4a6b4348159269f70c89194f5b","6715ba3d48d6479e94a09803b0d0f3b6","a1d4294e12d246a495140389a5e0fd08","99627cad0bdc4f78b4f9975ea536c7de","75f873eaa2f840959637ff3850b8071f","7cb862aa7b9b497a934632e9ef84c613"]},"outputId":"30ec1c11-0e81-40c5-9083-0897f8a32320","executionInfo":{"status":"ok","timestamp":1683392461309,"user_tz":-330,"elapsed":22394,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/18000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc28f8a36d44e57a92eefd10f7eac4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8967e5fed04643b392bee2987da6e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800ce60c32624fd98b0d2122c331b279"}},"metadata":{}}]},{"cell_type":"markdown","source":["Let's take a look at the new structure."],"metadata":{"id":"ih0q5287sxd6"}},{"cell_type":"code","execution_count":82,"metadata":{"id":"Cn186MJHXyDb","outputId":"a34982af-913b-4be6-b18b-4b206e1560a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683392461310,"user_tz":-330,"elapsed":25,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 18000\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 5000\n","    })\n","    val: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 2000\n","    })\n","})"]},"metadata":{},"execution_count":82}],"source":["tokenized_datasets"]},{"cell_type":"markdown","source":["We can see that the outer layer of the structure stayed the same but the naming of the columns has changed. \n","Let's take a look at the same random example we looked at previously only that it's preprocessed now."],"metadata":{"id":"YryGAtTJtQnh"}},{"cell_type":"code","source":["random_id = random.randint(0, 1000)\n","\n","print(\"Stars:\", imdb_review[\"train\"][random_id][\"sentiment\"])\n","print(\"Review:\", imdb_review[\"train\"][random_id][\"review\"])"],"metadata":{"id":"F2M0ICpr3TdC","outputId":"8e6e4a31-dc11-4873-d9ae-f5892100dafc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683392461310,"user_tz":-330,"elapsed":10,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Stars: 0\n","Review: I don't see enough TV game shows to understand the attraction of SHOW ME THE MONEY, but I suppose it holds some appeal for undemanding audiences. Ostensibly a quiz show, it offers contestants huge sums of money for answering a few simple questions. However, its quiz elements play only a small part in the proceedings, which I find tortuously complicated. For example, before answering a question, a contestant selects which question is to be asked by choosing from among random \\A,\\\" \\\"B,\\\" or \\\"C\\\" choices. Does this serve any purpose other than to slow the game down? It would be a lot quicker simply to start with \\\"A.\\\" Contestants can pass on questions, but must answer one of the three questions in each category.<br /><br />After responding to a question, the contestant is then asked to \\\"lock in\\\" the answer--another delaying tactic. The contestant's next task is to name which woman from about a dozen go-go dancers in cages is to unveil a card that indicates how much the question is worth. A correct answer adds the card's dollar figure to the contestant's running total; a wrong answer subtracts the same sum. This time-consuming step actually has some entertainment value, as it allows the audience to get a close look at the scantily clad and uniformly gorgeous dancers. Meanwhile, the contestant is reminded that an unlucky selection of the \\\"killer card\\\" will end the game instantly. This naturally makes the contestant sweat and causes further delays as the nervous contestant contemplates the sudden loss of the hundreds of thousands of dollars. My suspicion is that the possibility of sudden disaster is the show's chief audience appeal.<br /><br />Meanwhile, the whole process is slowed down even more by a lot of empty banter between host William Shatner and the contestant, along with occasional routines by the caged dancers. All these delays burn up so much time that it might be possible for audiences to forget what the original question is by the time the correct answer is revealed.<br /><br />A typical 30-minute episode of JEOPARDY often gets through as many as 60 questions. The first 30 minutes of SMTM that I watched got through only six questions (many of which pertained to other TV shows). No one in his right mind would watch this show because it's fun to play along by answering the questions at home. That leaves three possible reasons to watch the show.<br /><br />A. To see how a contestant responds to being on the verge of winning as much as one million dollars, only to lose everything in one stroke.<br /><br />B. To look at gorgeous young women performing sexually suggestive dance routines.<br /><br />C. To enjoy William Shatner's scintillating banter.<br /><br />My choice is \\\"B,\\\" but the women aren't on camera long enough to justify suffering through an hour of this show.\"\n"]}]},{"cell_type":"code","source":["print(\"Input IDS:\", tokenized_datasets[\"train\"][random_id][\"input_ids\"])\n","print(\"Input IDS:\", tokenized_datasets[\"train\"][random_id][\"attention_mask\"])\n","print(\"Labels:\", tokenized_datasets[\"train\"][random_id][\"labels\"])"],"metadata":{"id":"IKi4vb8VtoXF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea6a62f8-6f07-4e8a-c42b-292e350ebd57","executionInfo":{"status":"ok","timestamp":1683392461311,"user_tz":-330,"elapsed":8,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Input IDS: [101, 1045, 2123, 1005, 1056, 2156, 2438, 2694, 2208, 3065, 2000, 3305, 1996, 8432, 1997, 2265, 2033, 1996, 2769, 1010, 2021, 1045, 6814, 2009, 4324, 2070, 5574, 2005, 6151, 16704, 4667, 9501, 1012, 23734, 1037, 19461, 2265, 1010, 2009, 4107, 10584, 4121, 20571, 1997, 2769, 2005, 10739, 1037, 2261, 3722, 3980, 1012, 2174, 1010, 2049, 19461, 3787, 2377, 2069, 1037, 2235, 2112, 1999, 1996, 8931, 1010, 2029, 1045, 2424, 17153, 8525, 13453, 8552, 1012, 2005, 2742, 1010, 2077, 10739, 1037, 3160, 1010, 1037, 10832, 27034, 2029, 3160, 2003, 2000, 2022, 2356, 2011, 10549, 2013, 2426, 6721, 1032, 1037, 1010, 1032, 1000, 1032, 1000, 1038, 1010, 1032, 1000, 2030, 1032, 1000, 1039, 1032, 1000, 9804, 1012, 2515, 2023, 3710, 2151, 3800, 2060, 2084, 2000, 4030, 1996, 2208, 2091, 1029, 2009, 2052, 2022, 1037, 2843, 19059, 3432, 2000, 2707, 2007, 1032, 1000, 1037, 1012, 1032, 1000, 10584, 2064, 3413, 2006, 3980, 1010, 2021, 2442, 3437, 2028, 1997, 1996, 2093, 3980, 1999, 2169, 4696, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2044, 14120, 2000, 1037, 3160, 1010, 1996, 10832, 2003, 2059, 2356, 2000, 1032, 1000, 5843, 1999, 1032, 1000, 1996, 3437, 1011, 1011, 2178, 29391, 19717, 1012, 1996, 10832, 1005, 1055, 2279, 4708, 2003, 2000, 2171, 2029, 2450, 2013, 2055, 1037, 6474, 2175, 1011, 2175, 10487, 1999, 27157, 2003, 2000, 4895, 3726, 4014, 1037, 4003, 2008, 7127, 2129, 2172, 1996, 3160, 2003, 4276, 1012, 1037, 6149, 3437, 9909, 1996, 4003, 1005, 1055, 7922, 3275, 2000, 1996, 10832, 1005, 1055, 2770, 2561, 1025, 1037, 3308, 3437, 4942, 6494, 16649, 1996, 2168, 7680, 1012, 2023, 2051, 1011, 15077, 3357, 2941, 2038, 2070, 4024, 3643, 1010, 2004, 2009, 4473, 1996, 4378, 2000, 2131, 1037, 2485, 2298, 2012, 1996, 13594, 3775, 2135, 13681, 1998, 27423, 9882, 10487, 1012, 5564, 1010, 1996, 10832, 2003, 6966, 2008, 2019, 4895, 7630, 17413, 4989, 1997, 1996, 1032, 1000, 6359, 4003, 1032, 1000, 2097, 2203, 1996, 2208, 6880, 1012, 2023, 8100, 3084, 1996, 10832, 7518, 1998, 5320, 2582, 14350, 2004, 1996, 6091, 10832, 9530, 18532, 15725, 2015, 1996, 5573, 3279, 1997, 1996, 5606, 1997, 5190, 1997, 6363, 1012, 2026, 10928, 2003, 2008, 1996, 6061, 1997, 5573, 7071, 2003, 1996, 2265, 1005, 1055, 2708, 4378, 5574, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 5564, 1010, 1996, 2878, 2832, 2003, 9784, 2091, 2130, 2062, 2011, 1037, 2843, 1997, 4064, 7221, 3334, 2090, 3677, 2520, 21146, 18885, 1998, 1996, 10832, 1010, 2247, 2007, 8138, 23964, 2011, 1996, 7980, 2094, 10487, 1012, 2035, 2122, 14350, 6402, 2039, 2061, 2172, 2051, 2008, 2009, 2453, 2022, 2825, 2005, 9501, 2000, 5293, 2054, 1996, 2434, 3160, 2003, 2011, 1996, 2051, 1996, 6149, 3437, 2003, 3936, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1037, 5171, 2382, 1011, 3371, 2792, 1997, 26604, 2411, 4152, 2083, 2004, 2116, 2004, 3438, 3980, 1012, 1996, 2034, 2382, 2781, 1997, 15488, 21246, 2008, 1045, 3427, 2288, 2083, 2069, 2416, 3980, 1006, 2116, 1997, 2029, 2566, 28055, 2000, 2060, 2694, 3065, 1007, 1012, 2053, 2028, 1999, 2010, 2157, 2568, 2052, 3422, 2023, 2265, 2138, 2009, 1005, 1055, 4569, 2000, 2377, 2247, 102]\n","Input IDS: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Labels: 0\n"]}]},{"cell_type":"markdown","source":["Alright, the input text is transformed into a sequence of integers which can be transformed to word embeddings by the model, and the label index is simply shifted by -1."],"metadata":{"id":"wj93YOIZt21m"}},{"cell_type":"markdown","source":["## **Fine-tune the model**\n","\n","Having preprocessed the dataset, next we can fine-tune the model. We will make use of the popular [Hugging Face Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer) which allows us to start training in just a couple of lines of code. The Trainer can be used for more or less all tasks in PyTorch and is extremely convenient by taking care of a lot of boilerplate code needed for training.\n","\n"," Let's start by loading the model checkpoint using the convenient [`AutoModelForSequenceClassification`](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification). Since the checkpoint of the model repository is just a pretrained checkpoint we should define the size of the classification head by passing `num_lables=5` (since we have 5 sentiment classes)."],"metadata":{"id":"iJtybc-Vtj6E"}},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","model_repository = \"distilbert-base-uncased\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_repository, num_labels=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMoRk4l7-ecB","executionInfo":{"status":"ok","timestamp":1683392461968,"user_tz":-330,"elapsed":662,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}},"outputId":"60cccbe7-3124-4c82-ac28-b133f803e72e"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["Next, we load a data collator. A [data collator](https://huggingface.co/docs/transformers/main_classes/data_collator) is responsible for making sure each batch is correctly padded during training, which should happen dynamically since training samples are reshuffled before each epoch."],"metadata":{"id":"gS-NPpVQw60q"}},{"cell_type":"code","source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"-qKPqqN5z-Og","executionInfo":{"status":"ok","timestamp":1683392461968,"user_tz":-330,"elapsed":7,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["During training, it is important to monitor the performance of the model on a held-out validation set. To do so, we should pass a to define a `compute_metrics` function to the `Trainer` which is then called at each validation step during training.\n","\n","The simplest metric for the text classification task is *accuracy*, which simply states how much percent of the training samples were correctly classified. Using the *accuracy* metric might be problematic however if the validation or test data is very unbalanced. Let's verify quickly that this is not the case by counting the occurrences of each label."],"metadata":{"id":"3_3Vb2d0x0zO"}},{"cell_type":"code","source":["from collections import Counter\n","\n","print(\"Validation:\", Counter(tokenized_datasets[\"val\"][\"labels\"]))\n","print(\"Test:\", Counter(tokenized_datasets[\"test\"][\"labels\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Wx3Ey2PpAV6","outputId":"3d38b7d8-aefa-47be-86c1-521d8be16bc9","executionInfo":{"status":"ok","timestamp":1683392461968,"user_tz":-330,"elapsed":6,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation: Counter({1: 1027, 0: 973})\n","Test: Counter({0: 2507, 1: 2493})\n"]}]},{"cell_type":"markdown","source":["The validation and test data sets are as balanced as they can be, so we can safely use accuracy here!"],"metadata":{"id":"nAuDv6KFrT6r"}},{"cell_type":"markdown","source":[" Let's load the [accuracy metric](https://huggingface.co/metrics/accuracy) via the datasets library."],"metadata":{"id":"mwDmOVsbouee"}},{"cell_type":"code","source":["from datasets import load_metric\n","\n","accuracy = load_metric(\"accuracy\")"],"metadata":{"id":"VRZZppGj7TGo","executionInfo":{"status":"ok","timestamp":1683392463187,"user_tz":-330,"elapsed":1222,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":["Next, we define the `compute_metrics` which will be applied to the predicted outputs of the model which is of type [`EvalPrediction`](https://huggingface.co/docs/transformers/main/en/internal/trainer_utils#transformers.EvalPrediction) and therefore exposes the model's predictions and the gold labels.\n","We compute the predicted label class by taking the `argmax` of the model's prediction before passing it alongside the gold labels to the accuracy metric."],"metadata":{"id":"znHf9L5pzhJI"}},{"cell_type":"code","source":["import numpy as np\n","\n","def compute_metrics(pred):\n","    pred_logits = pred.predictions\n","    pred_classes = np.argmax(pred_logits, axis=-1)\n","    labels = np.asarray(pred.label_ids)\n","\n","    acc = accuracy.compute(predictions=pred_classes, references=labels)\n","\n","    return {\"accuracy\": acc[\"accuracy\"]}"],"metadata":{"id":"5BSKOnI27em2","executionInfo":{"status":"ok","timestamp":1683392463188,"user_tz":-330,"elapsed":4,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":["Great, now all components required for training are ready and all that's left to do is to define the hyper-parameters of the `Trainer`. We need to make sure that the model checkpoints are uploaded to the Hugging Face Hub during training. By setting `push_to_hub=True`, this is done automatically at every `save_steps` via the convenient [`push_to_hub`](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method.\n","\n","Besides, we define some standard hyper-parameters such as learning rate, warm-up steps and training epochs. We will log the loss every 500 steps and run evaluation every 5000 steps."],"metadata":{"id":"efyAC3zU0S0T"}},{"cell_type":"code","execution_count":90,"metadata":{"id":"Js3ZFkEDXyDc","executionInfo":{"status":"ok","timestamp":1683392463188,"user_tz":-330,"elapsed":3,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"imdbreviews_v1\",\n","    num_train_epochs=2, \n","    learning_rate=2e-5,\n","    warmup_steps=200,\n","    logging_steps=500,\n","    save_steps=5000,\n","    eval_steps=5000,\n","    evaluation_strategy=\"steps\",\n",")"]},{"cell_type":"markdown","source":["Putting it all together, we can finally instantiate the Trainer by passing all required components. We'll use the `\"validation\"` split as the held-out dataset during training."],"metadata":{"id":"K1SWtSpJ1WpZ"}},{"cell_type":"code","execution_count":91,"metadata":{"id":"4yWtH0xvXyDd","executionInfo":{"status":"ok","timestamp":1683392463188,"user_tz":-330,"elapsed":3,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    model=model,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"val\"]\n",")"]},{"cell_type":"markdown","source":["The Trainer is ready to go ðŸš€ You can start training by calling `trainer.train()`."],"metadata":{"id":"3LOkqNzi1tJ6"}},{"cell_type":"code","source":["train_metrics = trainer.train().metrics\n","trainer.save_metrics(\"train\", train_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"_M2oD-Z41NRZ","outputId":"473f4d4b-be52-4b4f-923f-85d7073f5ab9","executionInfo":{"status":"ok","timestamp":1683394060235,"user_tz":-330,"elapsed":1588249,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":92,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4500/4500 26:27, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Cool, we see that the model seems to learn something! Training loss and validation loss is going down and the accuracy also ends up being well over random chance (20%). Interestingly, we see accuracy of around **58.6 %** already after 5000 steps which doesn't improve that much anymore afterward. Choosing a bigger model or training for longer would have probably given better results here, but that's good enough for our hypothetical use case!\n","\n","Alright, finally let's upload the model checkpoint to the Hub."],"metadata":{"id":"CaLVY2nfmcgS"}},{"cell_type":"code","source":["trainer.save_model(\"./model/imdb_model\")"],"metadata":{"id":"WoCCkRyY5FqZ","executionInfo":{"status":"ok","timestamp":1683394401294,"user_tz":-330,"elapsed":1599,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["## **Evaluate / Analyse the model**\n","\n","Now that we have fine-tuned the model we need to be very careful about analyzing its performance. It's usually not enough to just look at basic metrics defining the quality of a model purely on a metric, such as *accuracy*.\n","The better approach is to find a metric that best describes the actual use case of the model.\n","\n","Let's dive into evaluating the model ðŸ¤¿."],"metadata":{"id":"FDg4g1vxvv4t"}},{"cell_type":"markdown","source":["The model has been uploaded to the Hub under [`deberta_v3_amazon_reviews`](https://huggingface.co/patrickvonplaten/deberta_v3_amazon_reviews) after training, so in a first step, let's download it from there again. If this notebook is run all at once the following cell will simply load the model from the cache."],"metadata":{"id":"wvefwWDdwkl4"}},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"./model/imdb_model\")"],"metadata":{"id":"HShL8goGqMYF","executionInfo":{"status":"ok","timestamp":1683394407819,"user_tz":-330,"elapsed":2152,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["The Trainer is not only an excellent class to train a model, but also to evaluate a model on a dataset. Let's instantiate the trainer with the same instances and functions as before, but this time there is no need to pass a training dataset."],"metadata":{"id":"r8HWjIBIxMlr"}},{"cell_type":"code","source":["trainer = Trainer(\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    model=model,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")"],"metadata":{"id":"Obfh0bBBl_Qj","executionInfo":{"status":"ok","timestamp":1683394413281,"user_tz":-330,"elapsed":512,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":["We use the Trainer's [`predict`]( ) function to evaluate the model on the test dataset on the same metric "],"metadata":{"id":"tj2jh-1uyOG0"}},{"cell_type":"code","source":["prediction_metrics = trainer.predict(tokenized_datasets[\"test\"]).metrics\n","prediction_metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"fiQnZSxvlAeV","outputId":"53f6d67e-ccd1-4314-b510-d893620942f0","executionInfo":{"status":"ok","timestamp":1683394493319,"user_tz":-330,"elapsed":74098,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":96,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'test_loss': 0.34345147013664246,\n"," 'test_accuracy': 0.9172,\n"," 'test_runtime': 73.9023,\n"," 'test_samples_per_second': 67.657,\n"," 'test_steps_per_second': 8.457}"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","source":["It does seem to generalize quite well to real-world data ðŸ”¥"],"metadata":{"id":"lDmOHbYVPIKe"}},{"cell_type":"markdown","source":["## Optimization\n","\n","As soon as you think the model's performance is good enough for production it's all about making the model as memory efficient and fast as possible.\n","\n","There are some obvious solutions to this like choosing the best suited accelerated hardware, *e.g.* better GPUs, making sure no gradients are computed during the forward pass, or lowering the precision, *e.g.* to float16. \n","\n","More advanced optimization methods include using open-source accelerator libraries such as [ONNX Runtime](https://onnxruntime.ai/index.html), [quantization](https://pytorch.org/docs/stable/quantization.html), and inference servers like [Triton](https://developer.nvidia.com/nvidia-triton-inference-server).\n","\n","At Hugging Face, we have been working a lot to facilitate the optimization of models, especially with our open-source [Optimum library](https://huggingface.co/hardware). Optimum makes it extremely simple to optimize most ðŸ¤— Transformers models.\n","\n","If you're looking for **highly optimized** solutions which don't require any technical knowledge, you might be interested in one of Hugging Face's paid inference services:\n","\n","- [Inference API](https://huggingface.co/inference-api)\n","- [Infinity](https://huggingface.co/infinity)"],"metadata":{"id":"JAmfpV6GRzHk"}}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5b192b92dd7946c79a88bc3b07715f30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78d24079e4da4ad086c0d6ffd2d157a1","IPY_MODEL_c0e065ad90cc4a559cec26bdc62611ce","IPY_MODEL_8d19102eafc44acc8b9ded87ec8bb054"],"layout":"IPY_MODEL_1c88b449ebce4f94afc378de9d924960"}},"78d24079e4da4ad086c0d6ffd2d157a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7af254fb9fb44f5a93a9aef5202205f","placeholder":"â€‹","style":"IPY_MODEL_a1354feaaac24603883b17fe92531998","value":"Downloading (â€¦)okenizer_config.json: 100%"}},"c0e065ad90cc4a559cec26bdc62611ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66afe8e29e4b41839202d14043c40d36","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bedac0c05af465a9866910311be9fef","value":28}},"8d19102eafc44acc8b9ded87ec8bb054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8fe9890489c448cb21c3037af3d08e4","placeholder":"â€‹","style":"IPY_MODEL_5e266556a5e8434fb92125bf04a93802","value":" 28.0/28.0 [00:00&lt;00:00, 782B/s]"}},"1c88b449ebce4f94afc378de9d924960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7af254fb9fb44f5a93a9aef5202205f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1354feaaac24603883b17fe92531998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66afe8e29e4b41839202d14043c40d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bedac0c05af465a9866910311be9fef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8fe9890489c448cb21c3037af3d08e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e266556a5e8434fb92125bf04a93802":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c76b0e8fd44f4add97490db7ceb6df63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63536cfa523d40b98f7ff1c7ac5b32a6","IPY_MODEL_f969b9baf0394d388fea39f284606527","IPY_MODEL_d5c3f19d02094c4186b355655979a0ea"],"layout":"IPY_MODEL_a4446dd2ea1f432ba4d7a10cffa22274"}},"63536cfa523d40b98f7ff1c7ac5b32a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7185b8bbf1564774a1cfc6c02e4d9347","placeholder":"â€‹","style":"IPY_MODEL_3ec310d7ebf54bd59b38c2fa5ae479e4","value":"Downloading (â€¦)solve/main/vocab.txt: 100%"}},"f969b9baf0394d388fea39f284606527":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c8d7f2b3054f01ae82e7b99332b53d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13974833fd594ba9b30c5c666bf5b9e1","value":231508}},"d5c3f19d02094c4186b355655979a0ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a65fdb09124421bbca14a844efbc584","placeholder":"â€‹","style":"IPY_MODEL_72c62f4a9af1468eabcda12e1ac493a7","value":" 232k/232k [00:00&lt;00:00, 1.41MB/s]"}},"a4446dd2ea1f432ba4d7a10cffa22274":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7185b8bbf1564774a1cfc6c02e4d9347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ec310d7ebf54bd59b38c2fa5ae479e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08c8d7f2b3054f01ae82e7b99332b53d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13974833fd594ba9b30c5c666bf5b9e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a65fdb09124421bbca14a844efbc584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72c62f4a9af1468eabcda12e1ac493a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4bdce5859c34e7bb4bb1a4c157f15d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d20f99f8c954ac08d69b654b90af433","IPY_MODEL_e42c818383df4c68a6e30e9beac7310d","IPY_MODEL_ba6a6d3ee3a8416797b2bb82f565ecae"],"layout":"IPY_MODEL_7e2423bfcec14c6684b6fc12934a3a2e"}},"8d20f99f8c954ac08d69b654b90af433":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75762a239d7a4bbfa1a8dac2b8fb185a","placeholder":"â€‹","style":"IPY_MODEL_bcc86a28ce474fb991ea12bdccd1e71b","value":"Downloading (â€¦)/main/tokenizer.json: 100%"}},"e42c818383df4c68a6e30e9beac7310d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d42a2eb1e5a4421ab7f98b361550bb2d","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b593508ddd254dc4a7307a9790f45d63","value":466062}},"ba6a6d3ee3a8416797b2bb82f565ecae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64dcb24cc59245bbb06247886951ad86","placeholder":"â€‹","style":"IPY_MODEL_40bd854226cd4c939da1e6e751165a6c","value":" 466k/466k [00:00&lt;00:00, 1.89MB/s]"}},"7e2423bfcec14c6684b6fc12934a3a2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75762a239d7a4bbfa1a8dac2b8fb185a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc86a28ce474fb991ea12bdccd1e71b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d42a2eb1e5a4421ab7f98b361550bb2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b593508ddd254dc4a7307a9790f45d63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64dcb24cc59245bbb06247886951ad86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40bd854226cd4c939da1e6e751165a6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bde3b8308e247f795bb8feb2fa1bd31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d16d60b60364a7e9030a8309e802661","IPY_MODEL_2ad4db497cd745dc856f699ba0bd16d2","IPY_MODEL_563387678b9f48ffb5b21b2c22041495"],"layout":"IPY_MODEL_aa0b8a7adcfb454287172ab77ab20bfe"}},"9d16d60b60364a7e9030a8309e802661":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edacec37cc294af0b4f6aef0230188c2","placeholder":"â€‹","style":"IPY_MODEL_ebea0751290a4531b0f6c73efbe8dd53","value":"Downloading (â€¦)lve/main/config.json: 100%"}},"2ad4db497cd745dc856f699ba0bd16d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_715e1b3fcb7a427aa003dc3d0fd8d589","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ca41bfa100f431dba8f97d3626006c5","value":483}},"563387678b9f48ffb5b21b2c22041495":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675bab324e6c4ec3b95059696fcdae4e","placeholder":"â€‹","style":"IPY_MODEL_f7b0882ecc2c48a1b42257ee39316686","value":" 483/483 [00:00&lt;00:00, 20.1kB/s]"}},"aa0b8a7adcfb454287172ab77ab20bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edacec37cc294af0b4f6aef0230188c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebea0751290a4531b0f6c73efbe8dd53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"715e1b3fcb7a427aa003dc3d0fd8d589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca41bfa100f431dba8f97d3626006c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"675bab324e6c4ec3b95059696fcdae4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b0882ecc2c48a1b42257ee39316686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbc28f8a36d44e57a92eefd10f7eac4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ba8fc08d4a742858d3cbfcc281c6cac","IPY_MODEL_d15a615e2fc7455088998592efa1bcde","IPY_MODEL_b392f9165c2148a0b53352c3f3ed7f23"],"layout":"IPY_MODEL_c9562cba11ab42cb8d2cd4a8cdf3033a"}},"1ba8fc08d4a742858d3cbfcc281c6cac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9a837e329e4d20a524c3ac23bc8643","placeholder":"â€‹","style":"IPY_MODEL_3ce6e759fb6d457b836bfa58d2422e54","value":"Map: 100%"}},"d15a615e2fc7455088998592efa1bcde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ab38cd80aa441499879577afaa678f","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ee75a5897ff4d3d9c19fd7383a47c0c","value":18000}},"b392f9165c2148a0b53352c3f3ed7f23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62f63c91ae7945be97e388393ca9b804","placeholder":"â€‹","style":"IPY_MODEL_a315d0cff5794162b66829806c133db9","value":" 18000/18000 [00:14&lt;00:00, 1317.98 examples/s]"}},"c9562cba11ab42cb8d2cd4a8cdf3033a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"2a9a837e329e4d20a524c3ac23bc8643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ce6e759fb6d457b836bfa58d2422e54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99ab38cd80aa441499879577afaa678f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ee75a5897ff4d3d9c19fd7383a47c0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62f63c91ae7945be97e388393ca9b804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a315d0cff5794162b66829806c133db9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a8967e5fed04643b392bee2987da6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59af80c824694b83b87887e37e953d2e","IPY_MODEL_edf3b148d23744589c6e18d33dd4d284","IPY_MODEL_07de1bab450942c7b3a43bafdc7ac58f"],"layout":"IPY_MODEL_dd42611eaad84f20b021e1d59ccd8dc9"}},"59af80c824694b83b87887e37e953d2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb589136d86e40409f048f4e3d2fe2e0","placeholder":"â€‹","style":"IPY_MODEL_490e6460672f4888b22f6f028781f916","value":"Map: 100%"}},"edf3b148d23744589c6e18d33dd4d284":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a35bb009d934cbd879f346ac678fece","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e67b7afa32f0498a8bf072c76f9f5378","value":5000}},"07de1bab450942c7b3a43bafdc7ac58f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad02b3c6318b486687f68577a5ded513","placeholder":"â€‹","style":"IPY_MODEL_1e14e1fb215549caa55b053c1a9082ac","value":" 5000/5000 [00:05&lt;00:00, 956.67 examples/s]"}},"dd42611eaad84f20b021e1d59ccd8dc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"eb589136d86e40409f048f4e3d2fe2e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490e6460672f4888b22f6f028781f916":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a35bb009d934cbd879f346ac678fece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e67b7afa32f0498a8bf072c76f9f5378":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad02b3c6318b486687f68577a5ded513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e14e1fb215549caa55b053c1a9082ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"800ce60c32624fd98b0d2122c331b279":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c141e31dbb2442ce8fe69e364296cb91","IPY_MODEL_aad9cf7df35e433a90eb4de22ae5e088","IPY_MODEL_46f1838f9ac948b28ffdb3911dddf0db"],"layout":"IPY_MODEL_8873125d0c81449f9354a24538991605"}},"c141e31dbb2442ce8fe69e364296cb91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb9e4d4a6b4348159269f70c89194f5b","placeholder":"â€‹","style":"IPY_MODEL_6715ba3d48d6479e94a09803b0d0f3b6","value":"Map: 100%"}},"aad9cf7df35e433a90eb4de22ae5e088":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1d4294e12d246a495140389a5e0fd08","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99627cad0bdc4f78b4f9975ea536c7de","value":2000}},"46f1838f9ac948b28ffdb3911dddf0db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75f873eaa2f840959637ff3850b8071f","placeholder":"â€‹","style":"IPY_MODEL_7cb862aa7b9b497a934632e9ef84c613","value":" 2000/2000 [00:01&lt;00:00, 1382.91 examples/s]"}},"8873125d0c81449f9354a24538991605":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"eb9e4d4a6b4348159269f70c89194f5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6715ba3d48d6479e94a09803b0d0f3b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1d4294e12d246a495140389a5e0fd08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99627cad0bdc4f78b4f9975ea536c7de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75f873eaa2f840959637ff3850b8071f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb862aa7b9b497a934632e9ef84c613":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}